packaging==23.2
torch==2.6.0
torchvision>=0.19.0
opencv-python>=4.9.0.80
diffusers>=0.31.0
transformers>=4.49.0
tokenizers>=0.20.3
accelerate>=1.1.1
tqdm
imageio
easydict
ftfy
dashscope
imageio-ffmpeg
https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.2.post1/flash_attn-2.7.2.post1+cu12torch2.6cxx11abiTRUE-cp310-cp310-linux_x86_64.whl
gradio>=5.0.0
numpy>=1.23.5,<2
xfuser>=0.4.1
protobuf